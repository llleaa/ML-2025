Load images dataset/eroded-dilated_0.67: 96 
[48, 69, 57, 4, 2, 42, 76, 34, 46, 18, 72, 55, 28, 94, 9, 15, 17, 26, 36, 95, 73, 5, 85, 20, 7, 90, 8, 40, 64, 19, 23, 81, 86, 63, 83, 91, 43, 14, 47, 51, 88, 6, 24, 65, 3, 70, 33, 92, 1, 12, 44, 53, 87, 58, 39, 22, 31, 77, 10, 29, 74, 13, 56, 89, 30, 80, 79, 66, 37, 11, 82, 49, 59, 25, 16, 75, 71, 67, 0, 50, 38, 41, 45, 60, 27, 35, 21, 78, 61, 32, 84, 62, 68, 54, 52, 93]
Number of image in Train: 76 | Val: 20
Pretrained model: None
UNet: 1677 number of trainable parameters of model 
Using device: cuda
Starting training for 1000 epochs...
Epoch [1/1000]  train_loss: 35.4937  val_loss: 16.9608 iou:0.2528  time: 1.35s lr: 1.00E-03
Epoch [2/1000]  train_loss: 34.4702  val_loss: 17.0370 iou:0.2528  time: 0.89s lr: 1.00E-03
Epoch [3/1000]  train_loss: 33.7188  val_loss: 17.0800 iou:0.2528  time: 0.81s lr: 1.00E-03
Epoch [4/1000]  train_loss: 33.1338  val_loss: 17.0834 iou:0.2528  time: 0.91s lr: 1.00E-03
Epoch [5/1000]  train_loss: 32.6806  val_loss: 17.0441 iou:0.2528  time: 0.91s lr: 1.00E-03
Epoch [6/1000]  train_loss: 32.3666  val_loss: 16.9757 iou:0.2528  time: 0.94s lr: 1.00E-03
Epoch [7/1000]  train_loss: 32.1541  val_loss: 16.8950 iou:0.2528  time: 0.96s lr: 1.00E-03
Epoch [8/1000]  train_loss: 31.9735  val_loss: 16.8074 iou:0.2528  time: 0.86s lr: 1.00E-03
Epoch [9/1000]  train_loss: 31.8179  val_loss: 16.7567 iou:0.2528  time: 0.83s lr: 1.00E-03
Epoch [10/1000]  train_loss: 31.6815  val_loss: 16.7230 iou:0.2528  time: 0.93s lr: 1.00E-03
Epoch [11/1000]  train_loss: 31.5547  val_loss: 16.6873 iou:0.2528  time: 0.93s lr: 1.00E-03
Epoch [12/1000]  train_loss: 31.4437  val_loss: 16.6468 iou:0.2528  time: 0.91s lr: 1.00E-03
Epoch [13/1000]  train_loss: 31.3356  val_loss: 16.6000 iou:0.2528  time: 0.91s lr: 1.00E-03
Epoch [14/1000]  train_loss: 31.2311  val_loss: 16.5490 iou:0.2528  time: 0.88s lr: 1.00E-03
Epoch [15/1000]  train_loss: 31.1339  val_loss: 16.4881 iou:0.2528  time: 0.89s lr: 1.00E-03
Epoch [16/1000]  train_loss: 31.0329  val_loss: 16.4261 iou:0.2528  time: 0.86s lr: 1.00E-03
Epoch [17/1000]  train_loss: 30.9376  val_loss: 16.3660 iou:0.2528  time: 0.88s lr: 1.00E-03
Epoch [18/1000]  train_loss: 30.8439  val_loss: 16.2984 iou:0.2528  time: 0.89s lr: 1.00E-03
Epoch [19/1000]  train_loss: 30.7554  val_loss: 16.2305 iou:0.2528  time: 0.91s lr: 1.00E-03
Epoch [20/1000]  train_loss: 30.6820  val_loss: 16.1775 iou:0.2528  time: 0.90s lr: 1.00E-03
Epoch [21/1000]  train_loss: 30.5884  val_loss: 16.1295 iou:0.2528  time: 0.92s lr: 1.00E-03
Epoch [22/1000]  train_loss: 30.5069  val_loss: 16.0695 iou:0.2528  time: 0.82s lr: 1.00E-03
Epoch [23/1000]  train_loss: 30.4375  val_loss: 15.9968 iou:0.2528  time: 0.83s lr: 1.00E-03
Epoch [24/1000]  train_loss: 30.3868  val_loss: 15.9193 iou:0.2528  time: 0.96s lr: 1.00E-03
Epoch [25/1000]  train_loss: 30.3095  val_loss: 15.8493 iou:0.2528  time: 0.88s lr: 1.00E-03
Epoch [26/1000]  train_loss: 30.2452  val_loss: 15.7791 iou:0.2528  time: 0.94s lr: 1.00E-03
Epoch [27/1000]  train_loss: 30.2084  val_loss: 15.6828 iou:0.2528  time: 0.94s lr: 1.00E-03
Epoch [28/1000]  train_loss: 30.1325  val_loss: 15.5991 iou:0.2528  time: 0.94s lr: 1.00E-03
Epoch [29/1000]  train_loss: 30.0846  val_loss: 15.5620 iou:0.2528  time: 0.93s lr: 1.00E-03
Epoch [30/1000]  train_loss: 30.0336  val_loss: 15.5601 iou:0.2528  time: 0.90s lr: 4.00E-04
Epoch [31/1000]  train_loss: 29.9993  val_loss: 15.5719 iou:0.2528  time: 0.90s lr: 4.00E-04
Epoch [32/1000]  train_loss: 29.9788  val_loss: 15.5919 iou:0.2528  time: 0.91s lr: 4.00E-04
Epoch [33/1000]  train_loss: 29.9607  val_loss: 15.6019 iou:0.2528  time: 0.93s lr: 4.00E-04
Epoch [34/1000]  train_loss: 29.9401  val_loss: 15.5961 iou:0.2528  time: 0.92s lr: 4.00E-04
Epoch [35/1000]  train_loss: 29.9194  val_loss: 15.5895 iou:0.2528  time: 0.94s lr: 1.60E-04
Epoch [36/1000]  train_loss: 29.9010  val_loss: 15.5782 iou:0.2528  time: 0.88s lr: 1.60E-04
Epoch [37/1000]  train_loss: 29.9062  val_loss: 15.5683 iou:0.2528  time: 0.89s lr: 1.60E-04
Epoch [38/1000]  train_loss: 29.8860  val_loss: 15.5606 iou:0.2528  time: 0.87s lr: 1.60E-04
Epoch [39/1000]  train_loss: 29.8797  val_loss: 15.5544 iou:0.2528  time: 0.81s lr: 1.60E-04
Epoch [40/1000]  train_loss: 29.8697  val_loss: 15.5470 iou:0.2528  time: 0.81s lr: 1.60E-04
Epoch [41/1000]  train_loss: 29.8662  val_loss: 15.5435 iou:0.2528  time: 0.85s lr: 1.60E-04
Epoch [42/1000]  train_loss: 29.8567  val_loss: 15.5362 iou:0.2528  time: 0.82s lr: 1.60E-04
Epoch [43/1000]  train_loss: 29.8504  val_loss: 15.5253 iou:0.2528  time: 0.85s lr: 6.40E-05
Epoch [44/1000]  train_loss: 29.8438  val_loss: 15.5188 iou:0.2528  time: 0.81s lr: 6.40E-05
Epoch [45/1000]  train_loss: 29.8555  val_loss: 15.5139 iou:0.2528  time: 0.87s lr: 6.40E-05
Epoch [46/1000]  train_loss: 29.8412  val_loss: 15.5096 iou:0.2528  time: 0.86s lr: 6.40E-05
Epoch [47/1000]  train_loss: 29.8392  val_loss: 15.5062 iou:0.2528  time: 0.85s lr: 6.40E-05
Epoch [48/1000]  train_loss: 29.8322  val_loss: 15.5022 iou:0.2528  time: 0.81s lr: 6.40E-05
Epoch [49/1000]  train_loss: 29.8270  val_loss: 15.4993 iou:0.2528  time: 0.84s lr: 6.40E-05
Epoch [50/1000]  train_loss: 29.8264  val_loss: 15.4948 iou:0.2528  time: 0.82s lr: 6.40E-05
Epoch [51/1000]  train_loss: 29.8238  val_loss: 15.4909 iou:0.2528  time: 0.84s lr: 2.56E-05
Epoch [52/1000]  train_loss: 29.8216  val_loss: 15.4890 iou:0.2528  time: 0.92s lr: 2.56E-05
Epoch [53/1000]  train_loss: 29.8263  val_loss: 15.4847 iou:0.2528  time: 0.91s lr: 2.56E-05
Epoch [54/1000]  train_loss: 29.8188  val_loss: 15.4814 iou:0.2528  time: 0.81s lr: 2.56E-05
Epoch [55/1000]  train_loss: 29.8121  val_loss: 15.4792 iou:0.2528  time: 0.90s lr: 2.56E-05
Epoch [56/1000]  train_loss: 29.8169  val_loss: 15.4769 iou:0.2528  time: 0.84s lr: 1.02E-05
Epoch [57/1000]  train_loss: 29.8144  val_loss: 15.4759 iou:0.2528  time: 0.82s lr: 1.02E-05
Epoch [58/1000]  train_loss: 29.8218  val_loss: 15.4764 iou:0.2528  time: 0.91s lr: 1.02E-05
Epoch [59/1000]  train_loss: 29.8197  val_loss: 15.4771 iou:0.2528  time: 0.83s lr: 1.02E-05
Epoch [60/1000]  train_loss: 29.8167  val_loss: 15.4782 iou:0.2528  time: 0.87s lr: 1.02E-05
Epoch [61/1000]  train_loss: 29.8184  val_loss: 15.4795 iou:0.2528  time: 0.85s lr: 1.02E-05
Epoch [62/1000]  train_loss: 29.8128  val_loss: 15.4795 iou:0.2528  time: 0.90s lr: 4.10E-06
Epoch [63/1000]  train_loss: 29.8165  val_loss: 15.4803 iou:0.2528  time: 0.81s lr: 4.10E-06
Epoch [64/1000]  train_loss: 29.8163  val_loss: 15.4810 iou:0.2528  time: 0.81s lr: 4.10E-06
Epoch [65/1000]  train_loss: 29.8114  val_loss: 15.4809 iou:0.2528  time: 0.89s lr: 4.10E-06
Epoch [66/1000]  train_loss: 29.8110  val_loss: 15.4805 iou:0.2528  time: 0.90s lr: 4.10E-06
Epoch [67/1000]  train_loss: 29.8119  val_loss: 15.4806 iou:0.2528  time: 0.84s lr: 1.64E-06
Epoch [68/1000]  train_loss: 29.8179  val_loss: 15.4795 iou:0.2528  time: 0.84s lr: 1.64E-06
Epoch [69/1000]  train_loss: 29.8113  val_loss: 15.4798 iou:0.2528  time: 0.87s lr: 1.64E-06
Epoch [70/1000]  train_loss: 29.8129  val_loss: 15.4794 iou:0.2528  time: 0.83s lr: 1.64E-06
Epoch [71/1000]  train_loss: 29.8111  val_loss: 15.4791 iou:0.2528  time: 0.81s lr: 1.64E-06
Epoch [72/1000]  train_loss: 29.8099  val_loss: 15.4792 iou:0.2528  time: 0.83s lr: 1.64E-06
Epoch [73/1000]  train_loss: 29.8104  val_loss: 15.4792 iou:0.2528  time: 0.82s lr: 6.55E-07
Epoch [74/1000]  train_loss: 29.8183  val_loss: 15.4788 iou:0.2528  time: 0.84s lr: 6.55E-07
Epoch [75/1000]  train_loss: 29.8105  val_loss: 15.4795 iou:0.2528  time: 0.88s lr: 6.55E-07
Epoch [76/1000]  train_loss: 29.8105  val_loss: 15.4785 iou:0.2528  time: 0.82s lr: 6.55E-07
Epoch [77/1000]  train_loss: 29.8078  val_loss: 15.4781 iou:0.2528  time: 0.85s lr: 6.55E-07
Epoch [78/1000]  train_loss: 29.8126  val_loss: 15.4780 iou:0.2528  time: 0.87s lr: 2.62E-07
Epoch [79/1000]  train_loss: 29.8117  val_loss: 15.4788 iou:0.2528  time: 0.84s lr: 2.62E-07
Epoch [80/1000]  train_loss: 29.8106  val_loss: 15.4790 iou:0.2528  time: 0.85s lr: 2.62E-07
Epoch [81/1000]  train_loss: 29.8102  val_loss: 15.4789 iou:0.2528  time: 0.91s lr: 2.62E-07
Epoch [82/1000]  train_loss: 29.8207  val_loss: 15.4797 iou:0.2528  time: 0.89s lr: 2.62E-07
Epoch [83/1000]  train_loss: 29.8130  val_loss: 15.4796 iou:0.2528  time: 0.89s lr: 2.62E-07
Epoch [84/1000]  train_loss: 29.8134  val_loss: 15.4787 iou:0.2528  time: 0.84s lr: 1.05E-07
Epoch [85/1000]  train_loss: 29.8158  val_loss: 15.4780 iou:0.2528  time: 0.85s lr: 1.05E-07
Epoch [86/1000]  train_loss: 29.8108  val_loss: 15.4783 iou:0.2528  time: 0.91s lr: 1.05E-07
Epoch [87/1000]  train_loss: 29.8340  val_loss: 15.4786 iou:0.2528  time: 0.89s lr: 1.05E-07
Epoch [88/1000]  train_loss: 29.8159  val_loss: 15.4785 iou:0.2528  time: 0.85s lr: 1.05E-07
Epoch [89/1000]  train_loss: 29.8249  val_loss: 15.4780 iou:0.2528  time: 0.85s lr: 1.05E-07
Epoch [90/1000]  train_loss: 29.8194  val_loss: 15.4780 iou:0.2528  time: 0.89s lr: 1.05E-07
Epoch [91/1000]  train_loss: 29.8212  val_loss: 15.4790 iou:0.2528  time: 1.03s lr: 1.05E-07
Epoch [92/1000]  train_loss: 29.8139  val_loss: 15.4788 iou:0.2528  time: 0.92s lr: 1.05E-07
Epoch [93/1000]  train_loss: 29.8209  val_loss: 15.4789 iou:0.2528  time: 0.93s lr: 4.19E-08
Best IoU on prediction: 0.4340
Worst IoU on prediction: 0.0830
[29, 69, 17, 27, 1, 30, 55, 57, 34, 35, 20, 66, 33, 64, 4, 60, 26, 51, 23, 25, 63, 73, 16, 41, 11, 71, 47, 46, 28, 65, 32, 52, 48, 39, 18, 3, 75, 58, 50, 40, 31, 59, 22, 5, 21, 45, 74, 0, 7, 68, 56, 2, 53, 54, 9, 49, 44, 72, 15, 38, 12, 10, 19, 67, 42, 37, 43, 24, 70, 36, 62, 8, 61, 14, 13, 6]
Number of image in Train: 56 | Val: 20
Pretrained model: None
UNet: 1677 number of trainable parameters of model 
Using device: cuda
Starting training for 1000 epochs...
