Load images dataset/eroded-dilated_0.57: 96 
[70, 41, 9, 33, 58, 54, 26, 88, 22, 12, 0, 21, 59, 82, 64, 92, 28, 11, 27, 43, 89, 68, 23, 44, 39, 65, 10, 25, 47, 60, 7, 53, 13, 85, 55, 40, 5, 57, 93, 16, 69, 24, 32, 2, 42, 83, 29, 38, 86, 14, 72, 46, 73, 31, 50, 49, 51, 78, 34, 84, 37, 90, 79, 36, 80, 45, 62, 18, 8, 81, 15, 91, 74, 66, 6, 35, 95, 77, 76, 52, 20, 1, 87, 4, 48, 75, 67, 17, 63, 56, 94, 71, 3, 30, 61, 19]
Number of image in Train: 76 | Val: 20
Pretrained model: None
UNet: 122021 number of trainable parameters of model 
Using device: cuda
Starting training for 1000 epochs...
Epoch [1/1000]  train_loss: 32.2779  val_loss: 16.2753 iou:0.2562  time: 1.44s lr: 1.00E-03
Epoch [2/1000]  train_loss: 30.8047  val_loss: 16.2600 iou:0.2562  time: 0.98s lr: 1.00E-03
Epoch [3/1000]  train_loss: 29.7605  val_loss: 16.2414 iou:0.2562  time: 1.01s lr: 1.00E-03
Epoch [4/1000]  train_loss: 29.0777  val_loss: 16.2196 iou:0.2562  time: 1.06s lr: 1.00E-03
Epoch [5/1000]  train_loss: 28.4027  val_loss: 16.1931 iou:0.2562  time: 0.93s lr: 1.00E-03
Epoch [6/1000]  train_loss: 27.6115  val_loss: 16.1602 iou:0.2562  time: 0.92s lr: 1.00E-03
Epoch [7/1000]  train_loss: 26.8802  val_loss: 16.1185 iou:0.2562  time: 0.90s lr: 1.00E-03
Epoch [8/1000]  train_loss: 26.2857  val_loss: 16.0181 iou:0.2562  time: 0.85s lr: 1.00E-03
Epoch [9/1000]  train_loss: 25.8360  val_loss: 15.7213 iou:0.2562  time: 0.94s lr: 1.00E-03
Epoch [10/1000]  train_loss: 25.4693  val_loss: 15.2950 iou:0.2562  time: 0.94s lr: 1.00E-03
Epoch [11/1000]  train_loss: 25.1481  val_loss: 14.7917 iou:0.2562  time: 0.95s lr: 1.00E-03
Epoch [12/1000]  train_loss: 24.8742  val_loss: 14.2783 iou:0.2562  time: 0.93s lr: 1.00E-03
Epoch [13/1000]  train_loss: 24.6540  val_loss: 13.8246 iou:0.2653  time: 1.02s lr: 1.00E-03
Epoch [14/1000]  train_loss: 24.4515  val_loss: 13.5002 iou:0.3491  time: 0.95s lr: 1.00E-03
Epoch [15/1000]  train_loss: 24.2483  val_loss: 13.2685 iou:0.4213  time: 0.95s lr: 1.00E-03
Epoch [16/1000]  train_loss: 24.0475  val_loss: 13.1279 iou:0.4155  time: 0.96s lr: 1.00E-03
Epoch [17/1000]  train_loss: 23.8689  val_loss: 13.2477 iou:0.3795  time: 0.96s lr: 1.00E-03
Epoch [18/1000]  train_loss: 23.7096  val_loss: 13.4660 iou:0.3387  time: 1.03s lr: 1.00E-03
Epoch [19/1000]  train_loss: 23.5180  val_loss: 13.5995 iou:0.3192  time: 0.97s lr: 1.00E-03
Epoch [20/1000]  train_loss: 23.3428  val_loss: 13.7178 iou:0.3109  time: 0.99s lr: 1.00E-03
Epoch [21/1000]  train_loss: 23.1655  val_loss: 13.8324 iou:0.3066  time: 0.98s lr: 1.00E-03
Epoch [22/1000]  train_loss: 22.9902  val_loss: 13.9452 iou:0.3044  time: 1.00s lr: 1.00E-03
Epoch [23/1000]  train_loss: 22.7966  val_loss: 13.9562 iou:0.3048  time: 0.98s lr: 1.00E-03
Epoch [24/1000]  train_loss: 22.6042  val_loss: 13.8815 iou:0.3059  time: 0.88s lr: 1.00E-03
Epoch [25/1000]  train_loss: 22.4013  val_loss: 13.5815 iou:0.3116  time: 1.01s lr: 1.00E-03
Epoch [26/1000]  train_loss: 22.2168  val_loss: 13.0183 iou:0.3680  time: 0.98s lr: 1.00E-03
Epoch [27/1000]  train_loss: 22.0744  val_loss: 12.4155 iou:0.6115  time: 0.99s lr: 1.00E-03
Epoch [28/1000]  train_loss: 21.8834  val_loss: 12.0731 iou:0.6392  time: 0.96s lr: 1.00E-03
Epoch [29/1000]  train_loss: 21.7122  val_loss: 12.0290 iou:0.6354  time: 0.97s lr: 1.00E-03
Epoch [30/1000]  train_loss: 21.5661  val_loss: 11.9990 iou:0.6395  time: 0.94s lr: 1.00E-03
Epoch [31/1000]  train_loss: 21.4142  val_loss: 12.0070 iou:0.6420  time: 1.02s lr: 1.00E-03
Epoch [32/1000]  train_loss: 21.3017  val_loss: 11.9591 iou:0.6502  time: 0.90s lr: 1.00E-03
Epoch [33/1000]  train_loss: 21.1977  val_loss: 12.1948 iou:0.6098  time: 1.00s lr: 1.00E-03
Epoch [34/1000]  train_loss: 21.0588  val_loss: 12.0517 iou:0.6256  time: 0.97s lr: 1.00E-03
Epoch [35/1000]  train_loss: 20.9517  val_loss: 12.3248 iou:0.5833  time: 0.92s lr: 1.00E-03
Epoch [36/1000]  train_loss: 20.8051  val_loss: 12.3781 iou:0.5358  time: 0.91s lr: 1.00E-03
Epoch [37/1000]  train_loss: 20.6870  val_loss: 11.9605 iou:0.6444  time: 0.93s lr: 1.00E-03
Epoch [38/1000]  train_loss: 20.5167  val_loss: 11.8357 iou:0.6776  time: 1.01s lr: 1.00E-03
Epoch [39/1000]  train_loss: 20.3872  val_loss: 11.7752 iou:0.6855  time: 0.97s lr: 1.00E-03
Epoch [40/1000]  train_loss: 20.2672  val_loss: 11.9401 iou:0.6702  time: 0.98s lr: 1.00E-03
Epoch [41/1000]  train_loss: 20.1446  val_loss: 11.9859 iou:0.6646  time: 0.89s lr: 1.00E-03
Epoch [42/1000]  train_loss: 20.0085  val_loss: 11.9419 iou:0.6684  time: 0.96s lr: 1.00E-03
Epoch [43/1000]  train_loss: 19.8969  val_loss: 11.9640 iou:0.6652  time: 1.04s lr: 1.00E-03
Epoch [44/1000]  train_loss: 19.7841  val_loss: 11.7817 iou:0.6849  time: 1.05s lr: 1.00E-03
Epoch [45/1000]  train_loss: 19.6773  val_loss: 11.6623 iou:0.6947  time: 0.95s lr: 1.00E-03
Epoch [46/1000]  train_loss: 19.6003  val_loss: 11.7567 iou:0.6800  time: 0.96s lr: 1.00E-03
Epoch [47/1000]  train_loss: 19.4491  val_loss: 11.9049 iou:0.6521  time: 0.98s lr: 1.00E-03
Epoch [48/1000]  train_loss: 19.3620  val_loss: 11.8663 iou:0.6576  time: 0.98s lr: 1.00E-03
Epoch [49/1000]  train_loss: 19.3587  val_loss: 11.7417 iou:0.6729  time: 0.97s lr: 1.00E-03
Epoch [50/1000]  train_loss: 19.1675  val_loss: 11.4772 iou:0.6906  time: 0.98s lr: 1.00E-03
Epoch [51/1000]  train_loss: 19.0580  val_loss: 11.3771 iou:0.6883  time: 0.95s lr: 4.00E-04
Epoch [52/1000]  train_loss: 18.9610  val_loss: 11.2662 iou:0.6963  time: 1.02s lr: 4.00E-04
Epoch [53/1000]  train_loss: 18.9099  val_loss: 11.1670 iou:0.7039  time: 1.04s lr: 4.00E-04
Epoch [54/1000]  train_loss: 18.8373  val_loss: 11.1300 iou:0.7034  time: 1.03s lr: 4.00E-04
Epoch [55/1000]  train_loss: 18.8319  val_loss: 11.0967 iou:0.7017  time: 0.98s lr: 4.00E-04
Epoch [56/1000]  train_loss: 18.7645  val_loss: 11.0771 iou:0.7000  time: 1.00s lr: 4.00E-04
Epoch [57/1000]  train_loss: 18.7147  val_loss: 11.0434 iou:0.7023  time: 0.97s lr: 4.00E-04
Epoch [58/1000]  train_loss: 18.6690  val_loss: 10.9940 iou:0.7042  time: 1.09s lr: 4.00E-04
Epoch [59/1000]  train_loss: 18.6030  val_loss: 11.0263 iou:0.6983  time: 0.89s lr: 4.00E-04
Epoch [60/1000]  train_loss: 18.5624  val_loss: 11.0171 iou:0.6960  time: 0.96s lr: 4.00E-04
Epoch [61/1000]  train_loss: 18.5093  val_loss: 10.9646 iou:0.6994  time: 0.97s lr: 1.60E-04
Epoch [62/1000]  train_loss: 18.4810  val_loss: 10.9035 iou:0.7039  time: 1.02s lr: 1.60E-04
Epoch [63/1000]  train_loss: 18.4754  val_loss: 10.8515 iou:0.7074  time: 0.97s lr: 1.60E-04
Epoch [64/1000]  train_loss: 18.4352  val_loss: 10.8512 iou:0.7070  time: 0.91s lr: 1.60E-04
Epoch [65/1000]  train_loss: 18.4192  val_loss: 10.8452 iou:0.7066  time: 0.93s lr: 1.60E-04
Epoch [66/1000]  train_loss: 18.4202  val_loss: 10.8324 iou:0.7062  time: 1.01s lr: 1.60E-04
Epoch [67/1000]  train_loss: 18.3874  val_loss: 10.8550 iou:0.7040  time: 0.97s lr: 1.60E-04
Epoch [68/1000]  train_loss: 18.3674  val_loss: 10.8621 iou:0.7031  time: 0.89s lr: 1.60E-04
Epoch [69/1000]  train_loss: 18.3495  val_loss: 10.8337 iou:0.7043  time: 1.04s lr: 1.60E-04
Epoch [70/1000]  train_loss: 18.3213  val_loss: 10.8372 iou:0.7032  time: 1.02s lr: 1.60E-04
Epoch [71/1000]  train_loss: 18.3021  val_loss: 10.8406 iou:0.7020  time: 0.92s lr: 1.60E-04
Epoch [72/1000]  train_loss: 18.2923  val_loss: 10.8192 iou:0.7021  time: 0.97s lr: 6.40E-05
Epoch [73/1000]  train_loss: 18.2732  val_loss: 10.8275 iou:0.7009  time: 0.96s lr: 6.40E-05
Epoch [74/1000]  train_loss: 18.2655  val_loss: 10.8134 iou:0.7012  time: 0.97s lr: 6.40E-05
Epoch [75/1000]  train_loss: 18.2641  val_loss: 10.7865 iou:0.7023  time: 0.98s lr: 6.40E-05
Epoch [76/1000]  train_loss: 18.2484  val_loss: 10.7775 iou:0.7027  time: 1.06s lr: 6.40E-05
Epoch [77/1000]  train_loss: 18.2421  val_loss: 10.7701 iou:0.7029  time: 0.95s lr: 2.56E-05
Epoch [78/1000]  train_loss: 18.2353  val_loss: 10.7615 iou:0.7027  time: 0.91s lr: 2.56E-05
Epoch [79/1000]  train_loss: 18.2313  val_loss: 10.7609 iou:0.7021  time: 0.89s lr: 2.56E-05
Epoch [80/1000]  train_loss: 18.2283  val_loss: 10.7670 iou:0.7016  time: 0.96s lr: 2.56E-05
Epoch [81/1000]  train_loss: 18.2250  val_loss: 10.7627 iou:0.7016  time: 1.01s lr: 2.56E-05
Epoch [82/1000]  train_loss: 18.2497  val_loss: 10.7889 iou:0.7004  time: 0.96s lr: 2.56E-05
Epoch [83/1000]  train_loss: 18.2192  val_loss: 10.7760 iou:0.7009  time: 0.96s lr: 1.02E-05
Epoch [84/1000]  train_loss: 18.2172  val_loss: 10.7743 iou:0.7012  time: 0.95s lr: 1.02E-05
Epoch [85/1000]  train_loss: 18.2163  val_loss: 10.7633 iou:0.7017  time: 0.95s lr: 1.02E-05
Epoch [86/1000]  train_loss: 18.2146  val_loss: 10.7580 iou:0.7020  time: 0.96s lr: 1.02E-05
Epoch [87/1000]  train_loss: 18.2554  val_loss: 10.7898 iou:0.7005  time: 0.98s lr: 1.02E-05
Epoch [88/1000]  train_loss: 18.2156  val_loss: 10.7711 iou:0.7013  time: 0.93s lr: 4.10E-06
Epoch [89/1000]  train_loss: 18.2105  val_loss: 10.7666 iou:0.7016  time: 0.94s lr: 4.10E-06
Epoch [90/1000]  train_loss: 18.2102  val_loss: 10.7669 iou:0.7015  time: 0.98s lr: 4.10E-06
Epoch [91/1000]  train_loss: 18.2149  val_loss: 10.7721 iou:0.7012  time: 0.95s lr: 4.10E-06
Epoch [92/1000]  train_loss: 18.2124  val_loss: 10.7565 iou:0.7019  time: 0.97s lr: 4.10E-06
Epoch [93/1000]  train_loss: 18.2094  val_loss: 10.7528 iou:0.7020  time: 0.96s lr: 4.10E-06
Epoch [94/1000]  train_loss: 18.2093  val_loss: 10.7447 iou:0.7024  time: 0.99s lr: 1.64E-06
Epoch [95/1000]  train_loss: 18.2238  val_loss: 10.7588 iou:0.7021  time: 0.99s lr: 1.64E-06
Epoch [96/1000]  train_loss: 18.2294  val_loss: 10.7320 iou:0.7033  time: 0.89s lr: 1.64E-06
Epoch [97/1000]  train_loss: 18.2133  val_loss: 10.7468 iou:0.7026  time: 0.90s lr: 1.64E-06
Epoch [98/1000]  train_loss: 18.2101  val_loss: 10.7403 iou:0.7027  time: 1.05s lr: 1.64E-06
Epoch [99/1000]  train_loss: 18.2189  val_loss: 10.7230 iou:0.7034  time: 0.96s lr: 1.64E-06
Epoch [100/1000]  train_loss: 18.2067  val_loss: 10.7251 iou:0.7033  time: 0.99s lr: 1.64E-06
Epoch [101/1000]  train_loss: 18.2065  val_loss: 10.7322 iou:0.7028  time: 1.04s lr: 1.64E-06
Epoch [102/1000]  train_loss: 18.2060  val_loss: 10.7311 iou:0.7027  time: 1.17s lr: 6.55E-07
Epoch [103/1000]  train_loss: 18.2193  val_loss: 10.7152 iou:0.7034  time: 0.91s lr: 6.55E-07
Epoch [104/1000]  train_loss: 18.2218  val_loss: 10.7009 iou:0.7041  time: 1.01s lr: 6.55E-07
Epoch [105/1000]  train_loss: 18.2064  val_loss: 10.7042 iou:0.7039  time: 0.95s lr: 6.55E-07
Epoch [106/1000]  train_loss: 18.2061  val_loss: 10.7109 iou:0.7037  time: 0.97s lr: 6.55E-07
Epoch [107/1000]  train_loss: 18.2067  val_loss: 10.7121 iou:0.7036  time: 0.99s lr: 2.62E-07
Epoch [108/1000]  train_loss: 18.2081  val_loss: 10.7260 iou:0.7030  time: 0.94s lr: 2.62E-07
Epoch [109/1000]  train_loss: 18.2123  val_loss: 10.7438 iou:0.7024  time: 0.91s lr: 2.62E-07
Epoch [110/1000]  train_loss: 18.2087  val_loss: 10.7503 iou:0.7021  time: 1.03s lr: 2.62E-07
Epoch [111/1000]  train_loss: 18.2082  val_loss: 10.7423 iou:0.7021  time: 1.02s lr: 2.62E-07
Epoch [112/1000]  train_loss: 18.2068  val_loss: 10.7484 iou:0.7017  time: 1.01s lr: 2.62E-07
Epoch [113/1000]  train_loss: 18.2159  val_loss: 10.7663 iou:0.7009  time: 0.96s lr: 1.05E-07
Epoch [114/1000]  train_loss: 18.2071  val_loss: 10.7665 iou:0.7012  time: 0.92s lr: 1.05E-07
Epoch [115/1000]  train_loss: 18.2136  val_loss: 10.7739 iou:0.7010  time: 0.98s lr: 1.05E-07
Epoch [116/1000]  train_loss: 18.2124  val_loss: 10.7765 iou:0.7011  time: 0.93s lr: 1.05E-07
Epoch [117/1000]  train_loss: 18.2434  val_loss: 10.7398 iou:0.7029  time: 0.97s lr: 1.05E-07
Epoch [118/1000]  train_loss: 18.2119  val_loss: 10.7290 iou:0.7031  time: 0.96s lr: 1.05E-07
Epoch [119/1000]  train_loss: 18.2066  val_loss: 10.7255 iou:0.7032  time: 0.95s lr: 1.05E-07
Epoch [120/1000]  train_loss: 18.2086  val_loss: 10.7382 iou:0.7027  time: 0.98s lr: 1.05E-07
Epoch [121/1000]  train_loss: 18.2055  val_loss: 10.7387 iou:0.7025  time: 0.92s lr: 1.05E-07
Epoch [122/1000]  train_loss: 18.2064  val_loss: 10.7445 iou:0.7022  time: 0.91s lr: 1.05E-07
Epoch [123/1000]  train_loss: 18.2278  val_loss: 10.7648 iou:0.7016  time: 0.95s lr: 4.19E-08
Best IoU on prediction: 0.6907
Worst IoU on prediction: 0.6258
[35, 0, 60, 19, 52, 32, 27, 39, 63, 56, 57, 20, 30, 44, 12, 3, 18, 4, 62, 24, 64, 26, 42, 6, 13, 1, 11, 73, 14, 28, 21, 9, 2, 29, 7, 38, 37, 53, 36, 54, 66, 46, 48, 70, 5, 58, 45, 23, 51, 61, 74, 34, 72, 55, 75, 25, 10, 40, 59, 71, 16, 8, 65, 43, 31, 15, 17, 69, 47, 41, 22, 33, 68, 49, 50, 67]
Number of image in Train: 56 | Val: 20
Pretrained model: None
UNet: 122021 number of trainable parameters of model 
Using device: cuda
Starting training for 1000 epochs...
